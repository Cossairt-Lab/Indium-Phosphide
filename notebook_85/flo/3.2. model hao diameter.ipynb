{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas library for the pandas dataframes\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "# Import Scikit-Learn library for decision tree models\n",
    "import sklearn \n",
    "\n",
    "from sklearn import datasets, linear_model, metrics, tree\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  RidgeCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "        \n",
    "# Dataset splitting        \n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_validate, RandomizedSearchCV\n",
    "\n",
    "# Errors\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>in_amount_mmol</th>\n",
       "      <th>p_amount_mmol</th>\n",
       "      <th>ligand_amount_mmol</th>\n",
       "      <th>first_sol_amount_ml</th>\n",
       "      <th>second_sol_amount_ml</th>\n",
       "      <th>third_sol_amount_ml</th>\n",
       "      <th>...</th>\n",
       "      <th>x6_zinc undecylenate</th>\n",
       "      <th>x7_None</th>\n",
       "      <th>x7_copper bromide</th>\n",
       "      <th>x7_oleic acid</th>\n",
       "      <th>x7_water</th>\n",
       "      <th>x7_zinc iodide</th>\n",
       "      <th>diameter_nm</th>\n",
       "      <th>abs_nm</th>\n",
       "      <th>emission_nm</th>\n",
       "      <th>Unnamed: 81</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195883</td>\n",
       "      <td>0.280681</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>-0.658075</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>610.0</td>\n",
       "      <td>688.5</td>\n",
       "      <td>78.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.299814</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>-0.589501</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>480.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.423738</td>\n",
       "      <td>0.134746</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>-0.425463</td>\n",
       "      <td>0.314284</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>492.0</td>\n",
       "      <td>546.5</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.423738</td>\n",
       "      <td>0.134746</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>-0.425463</td>\n",
       "      <td>0.314284</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>611.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.588970</td>\n",
       "      <td>1.448160</td>\n",
       "      <td>-0.323906</td>\n",
       "      <td>-0.535648</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>601.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>207</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>-0.093273</td>\n",
       "      <td>-0.485476</td>\n",
       "      <td>0.368027</td>\n",
       "      <td>2.081234</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>532.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>1.806899</td>\n",
       "      <td>0.353649</td>\n",
       "      <td>3.020436</td>\n",
       "      <td>2.425560</td>\n",
       "      <td>1.097051</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>560.0</td>\n",
       "      <td>603.5</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>209</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>7.590031</td>\n",
       "      <td>6.555877</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>2.769887</td>\n",
       "      <td>9.413951</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>587.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>210</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>0.154575</td>\n",
       "      <td>-0.376755</td>\n",
       "      <td>0.713993</td>\n",
       "      <td>4.491519</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>585.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>214</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>2.633061</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>4.173657</td>\n",
       "      <td>6.213152</td>\n",
       "      <td>4.521657</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>500.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0            1             1               1                 1   \n",
       "1           11            11              11                11   \n",
       "2           15            15              15                15   \n",
       "3           16            16              16                16   \n",
       "4           19            19              19                19   \n",
       "..         ...           ...             ...               ...   \n",
       "66         207           211             211               211   \n",
       "67         208           212             212               212   \n",
       "68         209           213             213               213   \n",
       "69         210           214             214               214   \n",
       "70         214           218             218               218   \n",
       "\n",
       "    in_amount_mmol  p_amount_mmol  ligand_amount_mmol  first_sol_amount_ml  \\\n",
       "0         0.195883       0.280681           -0.439228            -0.658075   \n",
       "1        -0.299814      -0.011188           -0.439228            -0.589501   \n",
       "2        -0.423738       0.134746           -0.439228            -0.425463   \n",
       "3        -0.423738       0.134746           -0.439228            -0.425463   \n",
       "4        -0.588970       1.448160           -0.323906            -0.535648   \n",
       "..             ...            ...                 ...                  ...   \n",
       "66       -0.093273      -0.485476            0.368027             2.081234   \n",
       "67        1.806899       0.353649            3.020436             2.425560   \n",
       "68        7.590031       6.555877           -0.439228             2.769887   \n",
       "69        0.154575      -0.376755            0.713993             4.491519   \n",
       "70        2.633061       0.718486            4.173657             6.213152   \n",
       "\n",
       "    second_sol_amount_ml  third_sol_amount_ml  ...  x6_zinc undecylenate  \\\n",
       "0              -0.370637            -0.096002  ...                     0   \n",
       "1              -0.370637            -0.096002  ...                     0   \n",
       "2               0.314284            -0.096002  ...                     0   \n",
       "3               0.314284            -0.096002  ...                     0   \n",
       "4              -0.370637            -0.096002  ...                     0   \n",
       "..                   ...                  ...  ...                   ...   \n",
       "66             -0.370637            -0.096002  ...                     0   \n",
       "67              1.097051            -0.096002  ...                     0   \n",
       "68              9.413951            -0.096002  ...                     0   \n",
       "69             -0.370637            -0.096002  ...                     0   \n",
       "70              4.521657            -0.096002  ...                     0   \n",
       "\n",
       "    x7_None  x7_copper bromide  x7_oleic acid  x7_water  x7_zinc iodide  \\\n",
       "0         1                  0              0         0               0   \n",
       "1         1                  0              0         0               0   \n",
       "2         1                  0              0         0               0   \n",
       "3         1                  0              0         0               0   \n",
       "4         1                  0              0         0               0   \n",
       "..      ...                ...            ...       ...             ...   \n",
       "66        1                  0              0         0               0   \n",
       "67        1                  0              0         0               0   \n",
       "68        1                  0              0         0               0   \n",
       "69        1                  0              0         0               0   \n",
       "70        1                  0              0         0               0   \n",
       "\n",
       "    diameter_nm  abs_nm  emission_nm  Unnamed: 81  \n",
       "0          2.61   610.0        688.5         78.5  \n",
       "1          1.70   480.0        518.0         38.0  \n",
       "2          3.60   492.0        546.5         54.5  \n",
       "3          4.60   611.0        634.0         23.0  \n",
       "4          2.50   601.0        695.0         94.0  \n",
       "..          ...     ...          ...          ...  \n",
       "66         2.70   532.0        591.0         59.0  \n",
       "67         2.40   560.0        603.5         43.5  \n",
       "68         5.00   587.0        609.0         22.0  \n",
       "69         4.00   585.0        630.0         45.0  \n",
       "70         2.70   500.0        595.0         95.0  \n",
       "\n",
       "[71 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dia = pd.read_csv(\"dataset_scaled_diameter.csv\")\n",
    "df_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for ML models\n",
    "\n",
    "input_col = ['in_amount_mmol', 'p_amount_mmol', 'ligand_amount_mmol',\n",
    "       'first_sol_amount_ml', 'second_sol_amount_ml', 'third_sol_amount_ml',\n",
    "       'other_1_amount_mmol', 'other_2_amount_mmol', 'total_volume_ml',\n",
    "       'temp_c', 'time_min', 'x0_chloroindium oxalate', 'x0_indium acetate',\n",
    "       'x0_indium bromide', 'x0_indium chloride', 'x0_indium iodide',\n",
    "       'x0_indium myristate', 'x0_indium oxalate', 'x0_indium palmitate',\n",
    "       'x0_indium trifluoroacetate',\n",
    "       'x0_indium tris(N,N-diisopropylacetamidinato)',\n",
    "       'x1_bis(trimethylsilyl)phosphine', 'x1_phosphine gas',\n",
    "       'x1_phosphorus trichloride', 'x1_sodium phosphide',\n",
    "       'x1_tris(diethylamino)phosphine', 'x1_tris(dimethylamino)phosphine',\n",
    "       'x1_tris(trimethylgermyl)phosphine', 'x1_tris(trimethylsilyl)phosphine',\n",
    "       'x1_white phosphorus', 'x2_None', 'x2_dodecanethiol', 'x2_lauric acid',\n",
    "       'x2_myristic acid', 'x2_oleic acid', 'x2_palmitic acid',\n",
    "       'x2_stearic acid', 'x3_4-ethylpyridine', 'x3_None',\n",
    "       'x3_dimethylformamide', 'x3_dodecylamine', 'x3_mesitylene',\n",
    "       'x3_octadecene', 'x3_oleylamine', 'x3_trioctylamine',\n",
    "       'x3_trioctylphosphine', 'x3_trioctylphosphine oxide', 'x4_None',\n",
    "       'x4_dioctyl ether', 'x4_dioctylamine', 'x4_hexadecylamine',\n",
    "       'x4_octylamine', 'x4_oleylamine', 'x4_toluene', 'x4_trioctylphosphine',\n",
    "       'x4_trioctylphosphine oxide', 'x5_None', 'x5_trioctylphosphine',\n",
    "       'x6_None', 'x6_acetic acid', 'x6_superhydride',\n",
    "       'x6_tetrabutylammonium myristate', 'x6_zinc acetate', 'x6_zinc bromide',\n",
    "       'x6_zinc chloride', 'x6_zinc iodide', 'x6_zinc octanoate',\n",
    "       'x6_zinc oleate', 'x6_zinc stearate', 'x6_zinc undecylenate', 'x7_None',\n",
    "       'x7_copper bromide', 'x7_oleic acid', 'x7_water', 'x7_zinc iodide',\n",
    "        'abs_nm','emission_nm'\n",
    "        ]\n",
    "\n",
    "output_col = ['diameter_nm']\n",
    "\n",
    "X = df_dia[input_col]\n",
    "\n",
    "Y = df_dia[output_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset for training\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=45, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:11<00:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1897979797979798 13 3 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Bagging algorithm. \n",
    "# Parameters are: max_depth, n_estimators, random_state.\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "\n",
    "min_i, min_j, min_k  = 0, 0, 0\n",
    "\n",
    "for i in tqdm(range(1, 21)):\n",
    "    for j in range(1, 21):\n",
    "        for k in range(5, 50, 5):\n",
    "            \n",
    "            B_regr = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=i),\n",
    "                                      n_estimators=j,\n",
    "                                      random_state=k)\n",
    "            \n",
    "            B_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "            B_Y_pred = B_regr.predict(X_test)\n",
    "            \n",
    "            mae = mean_absolute_error(Y_test, B_Y_pred)\n",
    "            \n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:00<00:00, 103.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1897979797979798 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_mae = 99999\n",
    "\n",
    "min_a  = 0\n",
    "\n",
    "for a in tqdm(range(1, 70)):\n",
    "    B_regr = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=13),\n",
    "                                      n_estimators=3,\n",
    "                                      random_state=a)\n",
    "    B_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "    B_Y_pred = B_regr.predict(X_test)\n",
    "            \n",
    "    mae = mean_absolute_error(Y_test, B_Y_pred)\n",
    "            \n",
    "    if (min_mae > mae):\n",
    "        min_mae = mae\n",
    "        min_a = a\n",
    "                \n",
    "print(min_mae, min_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:33<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2638076416337285 10 19 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Decision Trees algorithm. \n",
    "# Parameters are: max_depth, max_features, random_state.\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "\n",
    "min_i, min_j, min_k  = 0, 0, 0\n",
    "\n",
    "for i in tqdm(range(1, 21)):\n",
    "    for j in range(1, 21):\n",
    "        for k in range(5, 80, 5):\n",
    "            \n",
    "            DT_regr = DecisionTreeRegressor(max_depth=i,\n",
    "                                max_features=j,\n",
    "                                random_state=k)\n",
    "            \n",
    "            DT_regr.fit(X_train, Y_train)\n",
    "\n",
    "            DT_Y_pred = DT_regr.predict(X_test)\n",
    "\n",
    "            mae = mean_absolute_error(Y_test, DT_Y_pred)\n",
    "            \n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:11<00:00,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23323138251310513 7 11 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Random Forest algorithm. \n",
    "# Parameters are: max_depth, n_estimators, max_features.\n",
    "# Random_state is set to 45.\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "min_i, min_j, min_k = 0, 0, 0\n",
    "for i in tqdm(range(1, 21)):\n",
    "    for j in range(1, 21):\n",
    "        for k in range(2, 50, 2):\n",
    "            RF_regr = RandomForestRegressor(max_depth=i, \n",
    "                                            n_estimators=j, \n",
    "                                            max_features=k,\n",
    "                                            random_state=45\n",
    "                                                )\n",
    "            RF_regr.fit(X_train, np.ravel(Y_train))\n",
    "            RF_Y_pred = RF_regr.predict(X_test)\n",
    "\n",
    "            mae = mean_absolute_error(Y_test, RF_Y_pred)\n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error = 0.247 \n",
      " 0.173\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_regr = RandomForestRegressor(max_depth=10, \n",
    "                                n_estimators=2, \n",
    "                                max_features=42,\n",
    "                                random_state=45)\n",
    "            \n",
    "RF_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "RF_Y_pred = RF_regr.predict(X_test)\n",
    "            \n",
    "RF_mae = mean_absolute_error(Y_test, RF_Y_pred)\n",
    "RF_mse = mean_squared_error(Y_test, RF_Y_pred)\n",
    "print(\"Mean absolute error =\", round(RF_mae,3), '\\n', round(RF_mse,3))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.plot(Y_test, RF_Y_pred, 'o')\n",
    "plt.xlabel('Observed Values (nm)')\n",
    "plt.ylabel('Predicted Values (nm)')\n",
    "plt.plot([1,6],[1,6], color = 'r')\n",
    "plt.text(1, 5, 'MAE=' , fontdict=None)\n",
    "plt.text(1.49, 5, round(RF_mae,3) , fontdict=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:44<00:00,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2681818181818182 6 1 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Extra Trees algorithm. \n",
    "# Parameters are: random_state, n_estimators, max_features.\n",
    "\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "min_i, min_j, min_k = 0, 0, 0\n",
    "for i in tqdm(range(1, 21)):\n",
    "    for j in range(1, 21):\n",
    "        for k in range(2, 60, 2):\n",
    "            ET_regr = ExtraTreesRegressor(n_estimators=i, \n",
    "                                            max_features=j,\n",
    "                                            random_state=k\n",
    "                                                )\n",
    "            ET_regr.fit(X_train, np.ravel(Y_train))\n",
    "            ET_Y_pred = ET_regr.predict(X_test)\n",
    "\n",
    "            mae = mean_absolute_error(Y_test, ET_Y_pred)\n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:47<25:08, 167.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-16b8871d22ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mGB_regr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mGB_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mGB_Y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGB_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    215\u001b[0m                      check_input=False)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_mae = 999\n",
    "min_i, min_j, min_k, min_l = 0, 0, 0.0, 0\n",
    "for i in tqdm(range(300, 400, 10)):\n",
    "    for j in range(2, 40, 2):\n",
    "        for k in np.arange(0.04, 0.22, 0.02):\n",
    "            for l in range(2, 10, 2):\n",
    "                GB_regr = GradientBoostingRegressor(n_estimators=i, max_depth=j, learning_rate=k, random_state=l)\n",
    "                GB_regr.fit(X_train, np.ravel(Y_train))\n",
    "                GB_Y_pred = GB_regr.predict(X_test)\n",
    "\n",
    "                mae = mean_absolute_error(Y_test, GB_Y_pred)\n",
    "                if (min_mae > mae):\n",
    "                    min_mae = mae\n",
    "                    min_i = i\n",
    "                    min_j = j\n",
    "                    min_k = k\n",
    "                    min_l = l\n",
    "\n",
    "print(min_mae, min_i, min_j, min_k, min_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-nn\n",
      " MAE for diameter is  0.7563636363636366 \n",
      "\n",
      "Ridge\n",
      " MAE for diameter is  0.6253231781201205 \n",
      "\n",
      "Lasso\n",
      " MAE for diameter is  0.6448976800902813 \n",
      "\n",
      "ElasticNet\n",
      " MAE for diameter is  0.6564879495126625 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "REGRESSIONS = {\n",
    "    \"K-nn\": KNeighborsRegressor(),                          \n",
    "    \"Ridge\": RidgeCV(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(random_state=0),\n",
    "                }\n",
    "# mean absolute error is used to evaluate the performance of all regressions.\n",
    "\n",
    "\n",
    "for name, reg in REGRESSIONS.items():     \n",
    "    reg.fit(X_train, Y_train)                 \n",
    "    Y_pred = pd.DataFrame(reg.predict(X_test))\n",
    "    \n",
    "    print(name)\n",
    "    \n",
    "    mae = mean_absolute_error(Y_test, Y_pred)\n",
    "    \n",
    "    print(' MAE for diameter is ', mae, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging has the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_aug_diameter_Bagging.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_regr = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=13),\n",
    "                                      n_estimators=3,\n",
    "                                      random_state=10)\n",
    "            \n",
    "\n",
    "B_regr.fit(X_train, np.ravel(Y_train))\n",
    "B_Y_pred = B_regr.predict(X_test)\n",
    "\n",
    "joblib.dump(B_regr, \"./model_aug_diameter_Bagging.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
