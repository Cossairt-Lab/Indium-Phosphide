{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframe\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Scikit-Learn\n",
    "import sklearn \n",
    "from sklearn import datasets, linear_model, metrics, tree\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import (BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, \n",
    "RandomForestRegressor, AdaBoostRegressor)\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "        \n",
    "import joblib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>in_amount_mmol</th>\n",
       "      <th>p_amount_mmol</th>\n",
       "      <th>ligand_amount_mmol</th>\n",
       "      <th>first_sol_amount_ml</th>\n",
       "      <th>second_sol_amount_ml</th>\n",
       "      <th>third_sol_amount_ml</th>\n",
       "      <th>other_1_amount_mmol</th>\n",
       "      <th>other_2_amount_mmol</th>\n",
       "      <th>total_volume_ml</th>\n",
       "      <th>...</th>\n",
       "      <th>x6_zinc stearate</th>\n",
       "      <th>x6_zinc undecylenate</th>\n",
       "      <th>x7_None</th>\n",
       "      <th>x7_copper bromide</th>\n",
       "      <th>x7_oleic acid</th>\n",
       "      <th>x7_water</th>\n",
       "      <th>x7_zinc iodide</th>\n",
       "      <th>diameter_nm</th>\n",
       "      <th>abs_nm</th>\n",
       "      <th>emission_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.154575</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>-0.247025</td>\n",
       "      <td>-0.673379</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>0.865472</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>-0.660116</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>480</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.423738</td>\n",
       "      <td>-0.412509</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>-0.655198</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>0.457150</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>-0.651010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>560</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.423738</td>\n",
       "      <td>-0.412509</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>-0.655198</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>0.457150</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>-0.651010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>590</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.154575</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>-0.247025</td>\n",
       "      <td>-0.604513</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>0.865472</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>-0.596878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.154575</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>-0.247025</td>\n",
       "      <td>-0.604513</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>0.865472</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>-0.596878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>204</td>\n",
       "      <td>2.633061</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>5.134675</td>\n",
       "      <td>0.497332</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>-0.675365</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>0.407339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>530</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>208</td>\n",
       "      <td>-0.258506</td>\n",
       "      <td>-0.376025</td>\n",
       "      <td>0.137383</td>\n",
       "      <td>1.461446</td>\n",
       "      <td>1.097051</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>1.635891</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>1.482382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>562</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>211</td>\n",
       "      <td>-0.093273</td>\n",
       "      <td>-0.485476</td>\n",
       "      <td>0.368027</td>\n",
       "      <td>2.081234</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>-0.675365</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>1.861809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>532</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>214</td>\n",
       "      <td>0.154575</td>\n",
       "      <td>-0.376755</td>\n",
       "      <td>0.713993</td>\n",
       "      <td>4.491519</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>-0.675365</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>4.075133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>585</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>215</td>\n",
       "      <td>7.590031</td>\n",
       "      <td>7.504453</td>\n",
       "      <td>-0.439228</td>\n",
       "      <td>5.524499</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-0.096002</td>\n",
       "      <td>-0.675365</td>\n",
       "      <td>-0.146249</td>\n",
       "      <td>5.023700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>465</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  in_amount_mmol  p_amount_mmol  ligand_amount_mmol  \\\n",
       "0            0        0.154575      -0.011188           -0.247025   \n",
       "1            2       -0.423738      -0.412509           -0.439228   \n",
       "2            3       -0.423738      -0.412509           -0.439228   \n",
       "3            4        0.154575      -0.011188           -0.247025   \n",
       "4            5        0.154575      -0.011188           -0.247025   \n",
       "..         ...             ...            ...                 ...   \n",
       "80         204        2.633061       0.718486            5.134675   \n",
       "81         208       -0.258506      -0.376025            0.137383   \n",
       "82         211       -0.093273      -0.485476            0.368027   \n",
       "83         214        0.154575      -0.376755            0.713993   \n",
       "84         215        7.590031       7.504453           -0.439228   \n",
       "\n",
       "    first_sol_amount_ml  second_sol_amount_ml  third_sol_amount_ml  \\\n",
       "0             -0.673379             -0.370637            -0.096002   \n",
       "1             -0.655198             -0.370637            -0.096002   \n",
       "2             -0.655198             -0.370637            -0.096002   \n",
       "3             -0.604513             -0.370637            -0.096002   \n",
       "4             -0.604513             -0.370637            -0.096002   \n",
       "..                  ...                   ...                  ...   \n",
       "80             0.497332             -0.370637            -0.096002   \n",
       "81             1.461446              1.097051            -0.096002   \n",
       "82             2.081234             -0.370637            -0.096002   \n",
       "83             4.491519             -0.370637            -0.096002   \n",
       "84             5.524499             -0.370637            -0.096002   \n",
       "\n",
       "    other_1_amount_mmol  other_2_amount_mmol  total_volume_ml  ...  \\\n",
       "0              0.865472            -0.146249        -0.660116  ...   \n",
       "1              0.457150            -0.146249        -0.651010  ...   \n",
       "2              0.457150            -0.146249        -0.651010  ...   \n",
       "3              0.865472            -0.146249        -0.596878  ...   \n",
       "4              0.865472            -0.146249        -0.596878  ...   \n",
       "..                  ...                  ...              ...  ...   \n",
       "80            -0.675365            -0.146249         0.407339  ...   \n",
       "81             1.635891            -0.146249         1.482382  ...   \n",
       "82            -0.675365            -0.146249         1.861809  ...   \n",
       "83            -0.675365            -0.146249         4.075133  ...   \n",
       "84            -0.675365            -0.146249         5.023700  ...   \n",
       "\n",
       "    x6_zinc stearate  x6_zinc undecylenate  x7_None  x7_copper bromide  \\\n",
       "0                1.0                   0.0      1.0                0.0   \n",
       "1                0.0                   0.0      1.0                0.0   \n",
       "2                0.0                   0.0      1.0                0.0   \n",
       "3                0.0                   0.0      1.0                0.0   \n",
       "4                0.0                   0.0      1.0                0.0   \n",
       "..               ...                   ...      ...                ...   \n",
       "80               0.0                   0.0      1.0                0.0   \n",
       "81               0.0                   0.0      1.0                0.0   \n",
       "82               0.0                   0.0      1.0                0.0   \n",
       "83               0.0                   0.0      1.0                0.0   \n",
       "84               0.0                   0.0      1.0                0.0   \n",
       "\n",
       "    x7_oleic acid  x7_water  x7_zinc iodide  diameter_nm  abs_nm  emission_nm  \n",
       "0             0.0       0.0             0.0         None     480          539  \n",
       "1             0.0       0.0             0.0         None     560          595  \n",
       "2             0.0       0.0             0.0         None     590          635  \n",
       "3             0.0       0.0             0.0         None    None          500  \n",
       "4             0.0       0.0             0.0         None    None          520  \n",
       "..            ...       ...             ...          ...     ...          ...  \n",
       "80            0.0       0.0             0.0          2.4     530          579  \n",
       "81            0.0       0.0             0.0          3.5     562          618  \n",
       "82            0.0       0.0             0.0          2.7     532          591  \n",
       "83            0.0       0.0             0.0            4     585          630  \n",
       "84            0.0       0.0             0.0         None     465          550  \n",
       "\n",
       "[85 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emi = pd.read_csv(\"dataset_scaled_em.csv\")\n",
    "df_emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks the column names, and ensures that they do not have any leading or trailing spaces\n",
    "df_emi.columns = df_emi.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for ML models\n",
    "\n",
    "input_col = ['in_amount_mmol', 'p_amount_mmol', 'ligand_amount_mmol', 'first_sol_amount_ml', 'second_sol_amount_ml', \n",
    "             'third_sol_amount_ml', 'other_1_amount_mmol', 'other_2_amount_mmol', 'total_volume_ml', \n",
    "             'temp_c', 'time_min', 'x0_chloroindium oxalate', 'x0_indium acetate', 'x0_indium bromide', \n",
    "             'x0_indium chloride', 'x0_indium iodide', 'x0_indium myristate', 'x0_indium oxalate', \n",
    "             'x0_indium palmitate', 'x0_indium trifluoroacetate', 'x0_indium tris(N,N-diisopropylacetamidinato)', \n",
    "             'x1_bis(trimethylsilyl)phosphine', 'x1_phosphine gas', 'x1_phosphorus trichloride', 'x1_sodium phosphide', \n",
    "             'x1_tris(diethylamino)phosphine', 'x1_tris(dimethylamino)phosphine', 'x1_tris(trimethylgermyl)phosphine', \n",
    "             'x1_tris(trimethylsilyl)phosphine', 'x1_white phosphorus', 'x2_None', 'x2_dodecanethiol', \n",
    "             'x2_lauric acid', 'x2_myristic acid', 'x2_oleic acid', 'x2_palmitic acid', 'x2_stearic acid', \n",
    "             'x3_4-ethylpyridine', 'x3_None', 'x3_dimethylformamide', 'x3_dodecylamine', 'x3_mesitylene', \n",
    "             'x3_octadecene', 'x3_oleylamine', 'x3_trioctylamine', 'x3_trioctylphosphine', 'x3_trioctylphosphine oxide', \n",
    "             'x4_None', 'x4_dioctyl ether', 'x4_dioctylamine', 'x4_hexadecylamine', 'x4_hexadecylamine', \n",
    "             'x4_octylamine', 'x4_oleylamine', 'x4_toluene', 'x4_trioctylphosphine', 'x4_trioctylphosphine oxide', \n",
    "             'x5_None', 'x5_trioctylphosphine', 'x6_None', 'x6_acetic acid', 'x6_superhydride', \n",
    "             'x6_tetrabutylammonium myristate', 'x6_zinc acetate', 'x6_zinc bromide', 'x6_zinc chloride', \n",
    "             'x6_zinc iodide', 'x6_zinc octanoate', 'x6_zinc oleate', 'x6_zinc stearate', 'x6_zinc undecylenate', \n",
    "             'x7_None', 'x7_copper bromide', 'x7_oleic acid', 'x7_water', 'x7_zinc iodide']\n",
    "\n",
    "output_col = ['emission_nm']\n",
    "\n",
    "X = df_emi[input_col]\n",
    "\n",
    "Y = df_emi[output_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset for training\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=45, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9f3eafe7824a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                       random_state=k)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mB_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mB_Y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         all_results = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    371\u001b[0m                                \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             delayed(_parallel_build_estimators)(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_indices_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    143\u001b[0m             X_idx_sorted=\"deprecated\"):\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mccp_alpha\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Bagging algorithm. \n",
    "# Parameters are: max_depth, n_estimators, random_state.\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "\n",
    "min_i, min_j, min_k  = 0, 0, 0\n",
    "\n",
    "for i in tqdm(range(1, 30)):\n",
    "    for j in range(1, 30):\n",
    "        for k in range(2, 80, 2):\n",
    "            \n",
    "            B_regr = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=i),\n",
    "                                      n_estimators=j,\n",
    "                                      random_state=k)\n",
    "            \n",
    "            B_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "            B_Y_pred = B_regr.predict(X_test)\n",
    "            \n",
    "            mae = mean_absolute_error(Y_test, B_Y_pred)\n",
    "            \n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [02:48<00:00,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.87510734879156 4 24 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Decision Trees algorithm. \n",
    "# Parameters are: max_depth, max_features, random_state.\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "\n",
    "min_i, min_j, min_k  = 0, 0, 0\n",
    "\n",
    "for i in tqdm(range(1, 30)):\n",
    "    for j in range(1, 30):\n",
    "        for k in range(4, 70, 2):\n",
    "            \n",
    "            DT_regr = DecisionTreeRegressor(max_depth=i,\n",
    "                                max_features=j,\n",
    "                                random_state=k)\n",
    "            \n",
    "            DT_regr.fit(X_train, Y_train)\n",
    "\n",
    "            DT_Y_pred = DT_regr.predict(X_test)\n",
    "\n",
    "            mae = mean_absolute_error(Y_test, DT_Y_pred)\n",
    "            \n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "Best MAE Score Through Random Search : -41.109\n",
      "Best Parameters :  {'min_samples_split': 30, 'min_samples_leaf': 3}\n",
      "CPU times: user 2.81 s, sys: 94.5 ms, total: 2.91 s\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#sklearn random search\n",
    "\n",
    "params = {'min_samples_split': range(2,100),\n",
    "          'min_samples_leaf':range(1,100)}\n",
    "\n",
    "#n_jobs runs jobs in parallel, verbose prints updates\n",
    "rs_dt = RandomizedSearchCV(DecisionTreeRegressor(), param_distributions=params, n_iter=1000, n_jobs=-1, verbose=10,\n",
    "                          scoring='neg_mean_absolute_error')\n",
    "rs_dt.fit(X, np.ravel(Y))\n",
    "\n",
    "print('Best MAE Score Through Random Search : %.3f'%rs_dt.best_score_)\n",
    "print('Best Parameters : ',rs_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_regr = DecisionTreeRegressor(min_samples_splite=30, min_samples_leaf=3)\n",
    "            \n",
    "DT_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "DT_Y_pred = B_regr.predict(X_test)\n",
    "            \n",
    "DT_mae = mean_absolute_error(Y_test, DT_Y_pred)\n",
    "DT_mse = mean_squared_error(Y_test, DT_Y_pred)\n",
    "print(\"Mean absolute error =\", round(DT_mae,3), '\\n' \"Mean squared error =\", round(DT_mse,3))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.plot(Y_test, DT_Y_pred, 'o')\n",
    "plt.xlabel('Observed Values (nm)')\n",
    "plt.ylabel('Predicted Values (nm)')\n",
    "plt.plot([400,800],[400,800], color = 'r')\n",
    "plt.text(400, 750, 'MAE=' , fontdict=None)\n",
    "plt.text(440, 750, round(DT_mae,3) , fontdict=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [08:22<00:00, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.26153846153846 10 2 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Random Forest algorithm. \n",
    "# Parameters are: max_depth, n_estimators, max_features.\n",
    "# Random_state is set to 45.\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "min_i, min_j, min_k = 0, 0, 0\n",
    "for i in tqdm(range(1, 30)):\n",
    "    for j in range(1, 30):\n",
    "        for k in range(2, 60, 2):\n",
    "            RF_regr = RandomForestRegressor(max_depth=i, \n",
    "                                            n_estimators=j, \n",
    "                                            max_features=k,\n",
    "                                            random_state=45\n",
    "                                                )\n",
    "            RF_regr.fit(X_train, np.ravel(Y_train))\n",
    "            RF_Y_pred = RF_regr.predict(X_test)\n",
    "\n",
    "            mae = mean_absolute_error(Y_test, RF_Y_pred)\n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.02307692307692\n"
     ]
    }
   ],
   "source": [
    "RF_regr = RandomForestRegressor(max_depth=6, n_estimators=1, max_features=20, random_state=45)\n",
    "RF_regr.fit(X_train, np.ravel(Y_train))\n",
    "RF_Y_pred = RF_regr.predict(X_test)\n",
    "mae = mean_absolute_error(Y_test, RF_Y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 175.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.02307692307692 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_mae = 9999\n",
    "min_a = 0\n",
    "for a in tqdm(range(1,100)):\n",
    "    RF_regr = RandomForestRegressor(max_depth=6, n_estimators=1, max_features=20, random_state=a)\n",
    "    RF_regr.fit(X_train, np.ravel(Y_train))\n",
    "    RF_Y_pred = RF_regr.predict(X_test)\n",
    "    mae = mean_absolute_error(Y_test, RF_Y_pred)\n",
    "    if (min_mae > mae):\n",
    "        min_mae = mae\n",
    "        min_a = a\n",
    "print(min_mae, min_a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [17:28<00:00, 31.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.794871794871812 3 13 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a grid search for three parameters in the Extra Trees algorithm. \n",
    "# Parameters are: random_state, n_estimators, max_features.\n",
    "\n",
    "# This gives the best combination of the three parameters for the smallest mean squared error.\n",
    "\n",
    "min_mae = 99999\n",
    "min_i, min_j, min_k = 0, 0, 0\n",
    "for i in tqdm(range(1, 34)):\n",
    "    for j in range(1, 34):\n",
    "        for k in range(2, 60, 1):\n",
    "            ET_regr = ExtraTreesRegressor(n_estimators=i, \n",
    "                                            max_features=j,\n",
    "                                            random_state=k\n",
    "                                                )\n",
    "            ET_regr.fit(X_train, np.ravel(Y_train))\n",
    "            ET_Y_pred = ET_regr.predict(X_test)\n",
    "\n",
    "            mae = mean_absolute_error(Y_test, ET_Y_pred)\n",
    "            if (min_mae > mae):\n",
    "                min_mae = mae\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                min_k = k\n",
    "            \n",
    "print(min_mae, min_i, min_j, min_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error = 11.795 \n",
      "Mean squared error = 231.846\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ET_regr = ExtraTreesRegressor(n_estimators=3, \n",
    "                                            max_features=13,\n",
    "                                            random_state=51)\n",
    "            \n",
    "ET_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "ET_Y_pred = ET_regr.predict(X_test)\n",
    "            \n",
    "ET_mae = mean_absolute_error(Y_test, ET_Y_pred)\n",
    "ET_mse = mean_squared_error(Y_test, ET_Y_pred)\n",
    "print(\"Mean absolute error =\", round(ET_mae,3), '\\n' \"Mean squared error =\", round(ET_mse,3))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.plot(Y_test, ET_Y_pred, 'o')\n",
    "plt.xlabel('Observed Values (nm)')\n",
    "plt.ylabel('Predicted Values (nm)')\n",
    "plt.plot([400,800],[400,800], color = 'r')\n",
    "plt.text(400, 750, 'MAE=' , fontdict=None)\n",
    "plt.text(440, 750, round(ET_mae,3) , fontdict=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [08:23<00:00, 62.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.514535245824483 320 8 0.22000000000000003 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_mae = 999\n",
    "min_i, min_j, min_k, min_l = 0, 0, 0.0, 0\n",
    "for i in tqdm(range(320, 400, 10)):\n",
    "    for j in range(2, 24, 2):\n",
    "        for k in np.arange(0.08, 0.22, 0.02):\n",
    "            for l in range(2, 18, 4):\n",
    "                GB_regr = GradientBoostingRegressor(n_estimators=i, max_depth=j, learning_rate=k, random_state=l)\n",
    "                GB_regr.fit(X_train, np.ravel(Y_train))\n",
    "                GB_Y_pred = GB_regr.predict(X_test)\n",
    "\n",
    "                mae = mean_absolute_error(Y_test, GB_Y_pred)\n",
    "                if (min_mae > mae):\n",
    "                    min_mae = mae\n",
    "                    min_i = i\n",
    "                    min_j = j\n",
    "                    min_k = k\n",
    "                    min_l = l\n",
    "\n",
    "print(min_mae, min_i, min_j, min_k, min_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_regr = GradientBoostingRegressor(n_estimators=540, max_depth=4, learning_rate=0.18, random_state=67)\n",
    "\n",
    "            \n",
    "GB_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "GB_Y_pred = GB_regr.predict(X_test)\n",
    "            \n",
    "GB_mae = mean_absolute_error(Y_test, GB_Y_pred)\n",
    "print(\"Mean absolute error =\", round(GB_mae,3))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Gradient Boosting\")\n",
    "plt.plot(Y_test, GB_Y_pred, 'o')\n",
    "plt.xlabel('Observed Values (nm)')\n",
    "plt.ylabel('Predicted Values (nm)')\n",
    "plt.plot([400,800],[400,800], color = 'r')\n",
    "plt.text(400, 750, 'MAE=' , fontdict=None)\n",
    "plt.text(440, 750, round(GB_mae,3) , fontdict=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-nn\n",
      " MAE for diameter is  16.184615384615373 \n",
      "\n",
      "Ridge\n",
      " MAE for diameter is  18.110791212932252 \n",
      "\n",
      "Lasso\n",
      " MAE for diameter is  19.560952909058933 \n",
      "\n",
      "ElasticNet\n",
      " MAE for diameter is  18.19936624046899 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "REGRESSIONS = {\n",
    "    \"K-nn\": KNeighborsRegressor(),                          \n",
    "    \"Ridge\": RidgeCV(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(random_state=0),\n",
    "                }\n",
    "# mean absolute error is used to evaluate the performance of all regressions.\n",
    "\n",
    "\n",
    "for name, reg in REGRESSIONS.items():     \n",
    "    reg.fit(X_train, Y_train)                 \n",
    "    Y_pred = pd.DataFrame(reg.predict(X_test))\n",
    "    \n",
    "    print(name)\n",
    "    \n",
    "    mae = mean_absolute_error(Y_test, Y_pred)\n",
    "    \n",
    "    print(' MAE for diameter is ', mae, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree gave the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_aug_emission_ExtraTrees.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET_regr = ExtraTreesRegressor(n_estimators=3, \n",
    "                                            max_features=13,\n",
    "                                            random_state=51)\n",
    "            \n",
    "ET_regr.fit(X_train, np.ravel(Y_train))\n",
    "            \n",
    "ET_Y_pred = ET_regr.predict(X_test)\n",
    "            \n",
    "joblib.dump(ET_regr, \"./model_aug_emission_ExtraTrees.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
